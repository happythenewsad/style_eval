{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import random as rd\n",
    "\n",
    "path = \"data/shakespeare/data/align/plays/merged/\"\n",
    "\n",
    "aligned_style1 = path + \"othello_modern.snt.aligned\"\n",
    "aligned_style2 = path + \"othello_original.snt.aligned\"\n",
    "\n",
    "style1_tuples = unidecode.unidecode(open(aligned_style1).read())\n",
    "style2_tuples = unidecode.unidecode(open(aligned_style2).read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "style1_tuples = style1_tuples.split(\"\\n\")\n",
    "style2_tuples = style2_tuples.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll beat him until the welts look like basket-weave!\n",
      "I'll beat the knave into a twiggen bottle.\n"
     ]
    }
   ],
   "source": [
    "print(style1_tuples[1])\n",
    "print(style2_tuples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list lengths:  1855 1855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterkong/miniconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015924183161629923\n",
      "list lengths:  1855 1855\n",
      "0.016592648437224612\n",
      "list lengths:  1855 1855\n",
      "0.020607131527930533\n"
     ]
    }
   ],
   "source": [
    "def run_baseline(style1_tuples, style2_tuples, randm=False):\n",
    "    # orignal seems more verbose, so i'm having it be the reference\n",
    "    # range of this bleu function is 0 to 1\n",
    "    # vs. bleu score\n",
    "\n",
    "    print(\"list lengths: \", len(style1_tuples), len(style2_tuples))\n",
    "    howmany = len(style1_tuples)\n",
    "    bleus = []\n",
    "    for idx in range(howmany):\n",
    "        if randm:\n",
    "            sen2 = rd.sample(style2_tuples,1)[0]\n",
    "        else:\n",
    "            sen2 = style2_tuples[idx].split(' ')\n",
    "        sen1 = style1_tuples[idx].split(' ')\n",
    "        bleu = sentence_bleu([sen2],sen1)\n",
    "        bleus.append(bleu)\n",
    "\n",
    "\n",
    "    return sum(bleus)/howmany\n",
    "\n",
    "res = run_baseline(style1_tuples, style1_tuples, randm=True)\n",
    "print(res)\n",
    "res = run_baseline(style1_tuples, style2_tuples, randm=True)\n",
    "print(res)\n",
    "res = run_baseline(style2_tuples, style2_tuples, randm=True)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "817.4866385782897"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#style1 vs style2 averaged bleu: \n",
    ".44\n",
    "# randomized:\n",
    ".0175\n",
    "# use the absolute difference as a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n",
      "\n",
      "\n",
      "FooOrg 28 34 ORG\n",
      "$1 billion 39 49 MONEY\n",
      "John Smith 59 69 PERSON\n",
      "\n",
      "\n",
      "missed entities count: 0.3333333333333333, extraneous entities count: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "#NER\n",
    "# returns: list of ner sets. (pct missed entities, pct extraneous entities)\n",
    "# first arg is source, second is the candidate to be evaluated\n",
    "def ner_baseline(style1_tuples, style2_tuples, randm=False):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    howmany = len(style1_tuples)\n",
    "    ner_metrics = []\n",
    "    \n",
    "    for idx in range(howmany):\n",
    "        #print(\"----\")\n",
    "#         if randm:\n",
    "#             sen2 = rd.sample(style2_tuples,1)[0] #TODO\n",
    "#         else:\n",
    "#             sen2 = style2_tuples[idx].split(' ')\n",
    "\n",
    "        sen1_doc = nlp(style1_tuples[idx])\n",
    "        sen2_doc = nlp(style2_tuples[idx])\n",
    "        \n",
    "        for ent in sen1_doc.ents:\n",
    "            print(ent.text, ent.start_char, ent.end_char, ent.label_)     \n",
    "        print(\"\\n\")\n",
    "        for ent in sen2_doc.ents:\n",
    "            print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "            \n",
    "        src_entity_count = len(sen1_doc.ents)\n",
    "        targ_entity_count = len(sen2_doc.ents)\n",
    "        \n",
    "        sen1_ent_label_set = set([ent.label_ for ent in sen1_doc.ents])\n",
    "        sen2_ent_label_set = set([ent.label_ for ent in sen2_doc.ents])\n",
    "        \n",
    "        if src_entity_count == 0:\n",
    "            entity_coverage_pct = 1\n",
    "        else:\n",
    "            src_entities_not_in_target = len(sen1_ent_label_set.difference(sen2_ent_label_set))\n",
    "            entity_coverage_pct = src_entities_not_in_target/src_entity_count\n",
    " \n",
    "        if targ_entity_count == 0:\n",
    "            extraneous_entities_pct = 0\n",
    "        else:\n",
    "            extraneous_entities = len(sen2_ent_label_set.difference(sen1_ent_label_set))\n",
    "            extraneous_entities_pct = extraneous_entities/targ_entity_count\n",
    "        \n",
    "        ner_metrics.append((entity_coverage_pct, extraneous_entities_pct))\n",
    "    return ner_metrics    \n",
    "\n",
    "\n",
    "ner_metrics = ner_baseline(['Apple is looking at buying U.K. startup for $1 billion'], \n",
    "                          ['The company looks at buying FooOrg for $1 billion and also John Smith'], randm=True)\n",
    "#print(\"\\n\")\n",
    "#print(\"missed entities count: {}, extraneous entities count: {}\".format(ner_metrics[0][0],ner_metrics[0][1]))\n",
    "\n",
    "# shakespeare_aligned_ner_metrics = ner_baseline(style1_tuples, style2_tuples, randm=False)\n",
    "# shakespeare_nonaligned_ner_metrics = ner_baseline(style1_tuples, style2_tuples, randm=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shakespeare_aligned_ner_metrics_left = [elem[0] for elem in shakespeare_aligned_ner_metrics]\n",
    "#shakespeare_nonaligned_ner_metrics_left = [elem[0] for elem in shakespeare_nonaligned_ner_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601.2499999999998"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum(shakespeare_aligned_ner_metrics_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601.2499999999998"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum(shakespeare_nonaligned_ner_metrics_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1855)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the label for in-class rows is the character '1'\n",
    "\n",
    "import numpy as np\n",
    "in_class_labels = np.array(['1' for idx in range(len(style1_tuples))])\n",
    "X = np.array(style1_tuples)\n",
    "X_w_labels = np.vstack((X, in_class_labels))\n",
    "\n",
    "X_w_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {}\n",
    "dct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterkong/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/peterkong/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/peterkong/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
