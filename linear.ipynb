{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import random as rd\n",
    "\n",
    "play_file_infixes = ['othello', 'antony-and-cleopatra', 'asyoulikeit', \n",
    "                     'errors', 'hamlet', 'henryv', 'juliuscaesar', 'lear', 'macbeth', \n",
    "                     'merchant', 'msnd', 'muchado', 'richardiii', 'romeojuliet', \n",
    "                     'shrew', 'tempest', 'twelfthnight']\n",
    "play_file_infixes = ['othello', 'henryv']\n",
    "\n",
    "agg_original_tuples = []\n",
    "agg_modern_tuples = []\n",
    "path = \"data/shakespeare/data/align/plays/merged/\"\n",
    "\n",
    "for infix in play_file_infixes:\n",
    "    modern_tuples = unidecode.unidecode(open(path + infix + \"_modern.snt.aligned\").read()).split(\"\\n\")\n",
    "    original_tuples = unidecode.unidecode(open(path + infix + \"_original.snt.aligned\").read()).split(\"\\n\")\n",
    "    agg_original_tuples.extend(original_tuples)\n",
    "    agg_modern_tuples.extend(modern_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the matter, lieutenant?\n",
      "What's the matter, lieutenant?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"{}\\n{}\\n\".format(agg_original_tuples[0], agg_modern_tuples[0]))\n",
    "#print(\"{}\\n{}\\n\".format(agg_original_tuples[5000], agg_modern_tuples[5000]))\n",
    "# print(\"{}\\n{}\\n\".format(agg_original_tuples[9000], agg_modern_tuples[9000]))\n",
    "# print(\"{}\\n{}\\n\".format(agg_original_tuples[18000], agg_modern_tuples[18000]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5844, 2)\n"
     ]
    }
   ],
   "source": [
    "# in-class = original = '1'\n",
    "# raw -> (raw text, label)\n",
    "import numpy as np\n",
    "\n",
    "style1_np = np.array(agg_original_tuples)\n",
    "style1_labels = np.array(['ori' for x in range(len(agg_original_tuples))])\n",
    "X = np.vstack((style1_np, style1_labels))\n",
    "\n",
    "style2_np = np.array(agg_modern_tuples)\n",
    "style2_labels = np.array(['mod' for x in range(len(agg_modern_tuples))])\n",
    "X2 = np.vstack((style2_np, style2_labels))\n",
    "\n",
    "X = np.hstack((X,X2))\n",
    "raw = np.transpose(X)\n",
    "\n",
    "# idx_col = [str(x) for x in range(len(raw))]\n",
    "# idx_col = np.array(idx_col).reshape(-1,1)\n",
    "# print(idx_col.shape)\n",
    "print(raw.shape)\n",
    "#raw = np.hstack((idx_col, raw))\n",
    "raw.shape\n",
    "raw = np.random.permutation(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['No, great king.', 'ori'],\n",
       "       ['What, are you hurt, lieutenant?', 'ori'],\n",
       "       ['We are fortunate in the change.', 'mod'],\n",
       "       [\"But first, I have to tell you that Desdemona's completely in love with him.\",\n",
       "        'mod'],\n",
       "       ['He speaks bluntly, madam.', 'mod'],\n",
       "       ['Tis destiny unshunnable, like death.', 'ori'],\n",
       "       ['Wait for mine, sweet soul.', 'mod'],\n",
       "       ['When he is gone I would on great occasion speak with you.',\n",
       "        'ori'],\n",
       "       ['That she was false to wedlock?', 'ori'],\n",
       "       ['Yes, unfortunately.', 'mod']], dtype='<U549')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, great king. gold: ori {'sent_len': 15, 'NOUN_count': 1, 'ADV_count': 0, 'VERB_count': 0, 'ADJ_count': 1, 'adv_verb_ratio': 0, 'adj_noun_ratio': 1.0, 'INTJ_count': 1, 'PUNCT_count': 2, 'colon_count': 0, 'semicolon_count': 0, 'lparen_count': 0, 'ellipse_count': 0, 'quote_count': 0}\n",
      "\n",
      "I will hear further reason for this. gold: ori {'sent_len': 36, 'NOUN_count': 1, 'ADV_count': 0, 'VERB_count': 2, 'ADJ_count': 1, 'adv_verb_ratio': 0, 'adj_noun_ratio': 1.0, 'PRON_count': 1, 'ADP_count': 1, 'DET_count': 1, 'PUNCT_count': 1, 'colon_count': 0, 'semicolon_count': 0, 'lparen_count': 0, 'ellipse_count': 0, 'quote_count': 0}\n",
      "\n",
      "Good love, call him back. gold: ori {'sent_len': 25, 'NOUN_count': 1, 'ADV_count': 1, 'VERB_count': 1, 'ADJ_count': 1, 'adv_verb_ratio': 1.0, 'adj_noun_ratio': 1.0, 'PUNCT_count': 2, 'PRON_count': 1, 'colon_count': 0, 'semicolon_count': 0, 'lparen_count': 0, 'ellipse_count': 0, 'quote_count': 0}\n",
      "\n",
      "Go, and bring them. gold: ori {'sent_len': 19, 'NOUN_count': 0, 'ADV_count': 0, 'VERB_count': 2, 'ADJ_count': 0, 'adv_verb_ratio': 0, 'adj_noun_ratio': 0, 'PUNCT_count': 2, 'CCONJ_count': 1, 'PRON_count': 1, 'colon_count': 0, 'semicolon_count': 0, 'lparen_count': 0, 'ellipse_count': 0, 'quote_count': 0}\n",
      "\n",
      "Shame, and eternal shame, nothing but shame! gold: ori {'sent_len': 44, 'NOUN_count': 4, 'ADV_count': 0, 'VERB_count': 0, 'ADJ_count': 1, 'adv_verb_ratio': 0, 'adj_noun_ratio': 4.0, 'PUNCT_count': 3, 'CCONJ_count': 1, 'ADP_count': 1, 'colon_count': 0, 'semicolon_count': 0, 'lparen_count': 0, 'ellipse_count': 0, 'quote_count': 0}\n",
      "\n",
      "Why, you silly man! gold: mod {'sent_len': 19, 'NOUN_count': 1, 'ADV_count': 1, 'VERB_count': 0, 'ADJ_count': 1, 'adv_verb_ratio': 0, 'adj_noun_ratio': 1.0, 'PUNCT_count': 2, 'PRON_count': 1, 'colon_count': 0, 'semicolon_count': 0, 'lparen_count': 0, 'ellipse_count': 0, 'quote_count': 0}\n",
      "\n",
      "(5844, 23)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import spacy\n",
    "import scipy.sparse\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "features = []\n",
    "\n",
    "# feature engineering\n",
    "    # construct index column\n",
    "# idx_col = np.array([raw[:,0]])\n",
    "# idx_col = idx_col.astype('f', copy=True)\n",
    "\n",
    "#bleu: 0-1, 1 is perfect score\n",
    "#bleu = sentence_bleu([sen2],sen1)\n",
    "\n",
    "raw_text_col = 0\n",
    "LABEL_COL = -1\n",
    "\n",
    "def extract_feats(row_idx, raw):\n",
    "    feature_dict = {}\n",
    "    punc_dict = {'colon_count': 0, 'semicolon_count':0, 'lparen_count': 0,\n",
    "                 'ellipse_count': 0, 'quote_count': 0}\n",
    "    pos_dict = {'NOUN_count': 0, 'ADV_count': 0, 'VERB_count': 0, \n",
    "                'ADJ_count': 0, 'adv_verb_ratio': 0, 'adj_noun_ratio': 0\n",
    "               }\n",
    "    txt = str(raw[row_idx][raw_text_col])\n",
    "    \n",
    "    feature_dict['sent_len'] = len(txt)\n",
    "    try:\n",
    "        doc = nlp(txt)\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        print(\"offending message [{}], len: {}, row idx: {}\".format(txt, len(txt), row_idx))\n",
    "\n",
    "    for token in doc:\n",
    "        pos = token.pos_\n",
    "        pos_dict[pos+'_count'] = pos_dict.get(pos+'_count', 0) + 1\n",
    "\n",
    "    #      import re\n",
    "    #     p = re.compile('\\'')\n",
    "    #     p.findall(\"' ' '\")\n",
    "\n",
    "    if pos_dict['NOUN_count'] == 0 or pos_dict['ADJ_count'] == 0:\n",
    "        pos_dict['adj_noun_ratio'] = 0\n",
    "    else:\n",
    "        pos_dict['adj_noun_ratio'] = pos_dict['NOUN_count'] / pos_dict['ADJ_count'] \n",
    "\n",
    "    if pos_dict['VERB_count'] == 0 or pos_dict['ADV_count'] == 0:\n",
    "        pos_dict['adv_verb_ratio'] = 0\n",
    "    else:\n",
    "        pos_dict['adv_verb_ratio'] = pos_dict['VERB_count'] / pos_dict['ADV_count'] \n",
    "        \n",
    "    feature_dict.update(pos_dict)\n",
    "    feature_dict.update(punc_dict)\n",
    "    \n",
    "    if row_idx % 1000 == 0:\n",
    "        print(\"{} gold: {} {}\\n\".format(txt, raw[row_idx][LABEL_COL], feature_dict) )\n",
    "     \n",
    "    return feature_dict\n",
    "\n",
    "\n",
    "for row_idx,_ in enumerate(raw):\n",
    "    features.append(extract_feats(row_idx, raw))\n",
    "\n",
    "#labels_col = np.array([raw[:,LABEL_COL]])\n",
    "\n",
    "X = vectorizer.fit_transform(features)\n",
    "print(X.shape)\n",
    "\n",
    "#X = scipy.sparse.hstack(( idx_col.T, X, labels_col.T ))\n",
    "X = X.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 5844 train val split delim: 4675 val test split delim: 5259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "\n",
    "import time\n",
    "import math\n",
    "###############\n",
    "# training ####\n",
    "###############\n",
    "# test breakout: 3500, 210\n",
    "train_val_split_delim = math.floor(len(X) * .8)\n",
    "val_test_split_delim = math.floor(len(X) * .9)\n",
    "print(\"total rows: {} train val split delim: {} val test split delim: {}\".format(len(X), train_val_split_delim, val_test_split_delim))\n",
    "# numpy note: addressing [:delim] is exclusive of delim, but\n",
    "#                         [delim:] is inclusive of delim\n",
    "\n",
    "\n",
    "X_train = X[0:train_val_split_delim]\n",
    "Y_train = raw[0:train_val_split_delim,LABEL_COL]\n",
    "\n",
    "X_val = X[train_val_split_delim:val_test_split_delim]\n",
    "Y_val = raw[train_val_split_delim:val_test_split_delim,LABEL_COL]\n",
    "\n",
    "X_test = X[val_test_split_delim:]\n",
    "Y_test = raw[val_test_split_delim:,LABEL_COL]\n",
    "\n",
    "if len(X_test) != len(Y_test):\n",
    "    raise ValueError(\"mismatched arrays! {} {}\".format(len(preds), len(y_true)))\n",
    "\n",
    "\n",
    "#mdl = LogisticRegression(random_state=123)\n",
    "#mdl = MultinomialNB()\n",
    "mdl = svm.SVC(kernel = 'linear', C=.1) # Accuracy: 0.589743\n",
    "mdl.fit(X_train, Y_train)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5897435897435898\n",
      "Predictions evaluated: 585\n"
     ]
    }
   ],
   "source": [
    "# evaluation ###\n",
    "################\n",
    "#second class is original\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "#y_true = raw[train_val_split_delim:val_test_split_delim,LABEL_COL]\n",
    "preds = mdl.predict(X_test)\n",
    "#y_true = [int(raw[int(idx)][-1]) for idx in val_indices]\n",
    "\n",
    "# brier = brier_score_loss(y_true, preds[:,0]) \n",
    "# print(\"brier score:\", brier)\n",
    "\n",
    "#currently slightly worse than randomly permuting preds\n",
    "\n",
    "def accuracy(preds, y_true):\n",
    "    \n",
    "    if len(preds) != len(y_true):\n",
    "        raise ValueError(\"mismatched arrays! {} {}\".format(len(preds), len(y_true)))\n",
    "    num_correct = 0\n",
    "    for (x,y) in zip(preds, y_true):\n",
    "        if x == y:\n",
    "            num_correct = num_correct + 1\n",
    "    return num_correct/len(preds)\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy(preds,Y_test)))\n",
    "print(\"Predictions evaluated: {}\".format(len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error analysis ##\n",
    "##################\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "conf_mat = confusion_matrix(y_true, preds)\n",
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# # sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "# #             xticklabels=category_id_df.Product.values, yticklabels=category_id_df.Product.values)\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "\n",
    "# NOTE: this function taken from: \n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = 80\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "print(conf_mat)\n",
    "plot_confusion_matrix(conf_mat, classes=mdl.classes_,\n",
    "                      title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_len = len(preds)\n",
    "# accuracy = sum(preds)/float(test_len)\n",
    "# print(\"accuracy: {}\".format(accuracy))\n",
    "\n",
    "#othello accuracy: 0.7428571428571429. but maybe not permuted\n",
    "#all: accuracy: 0.328237942884228\n",
    "\n",
    "#pos, no bleu, 2 plays\n",
    "# Mult NB: .519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\", \"'\", \"'\"]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "p = re.compile('\\'')\n",
    "p.findall(\"' ' '\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
