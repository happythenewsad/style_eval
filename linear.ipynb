{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import random as rd\n",
    "\n",
    "play_file_infixes = ['othello', 'antony-and-cleopatra', 'asyoulikeit', \n",
    "                     'errors', 'hamlet', 'henryv', 'juliuscaesar', 'lear', 'macbeth', \n",
    "                     'merchant', 'msnd', 'muchado', 'richardiii', 'romeojuliet', \n",
    "                     'shrew', 'tempest', 'twelfthnight']\n",
    "\n",
    "agg_original_tuples = []\n",
    "agg_modern_tuples = []\n",
    "path = \"data/shakespeare/data/align/plays/merged/\"\n",
    "\n",
    "for infix in play_file_infixes:\n",
    "    modern_tuples = unidecode.unidecode(open(path + infix + \"_modern.snt.aligned\").read()).split(\"\\n\")\n",
    "    original_tuples = unidecode.unidecode(open(path + infix + \"_original.snt.aligned\").read()).split(\"\\n\")\n",
    "    agg_original_tuples.extend(original_tuples)\n",
    "    agg_modern_tuples.extend(modern_tuples)\n",
    "# aligned_othello_style1 = \"data/shakespeare/data/align/plays/merged/othello_modern.snt.aligned\"\n",
    "# aligned_othello_style2 = \"data/shakespeare/data/align/plays/merged/othello_original.snt.aligned\"\n",
    "\n",
    "# aligned_ant_cleo_style1 = \"data/shakespeare/data/align/plays/merged/antony-and-cleopatra_modern.snt.aligned\"\n",
    "# aligned_ant_cleo_style2 = \"data/shakespeare/data/align/plays/merged/antony-and-cleopatra_original.snt.aligned\"\n",
    "\n",
    "# aligned_asyoulikeit_style1 = \"data/shakespeare/data/align/plays/merged/asyoulikeit_modern.snt.aligned\"\n",
    "# aligned_asyoulikeit_style2 = \"data/shakespeare/data/align/plays/merged/asyoulikeit_original.snt.aligned\"\n",
    "\n",
    "# aligned_errors_style1 = \"data/shakespeare/data/align/plays/merged/errors_modern.snt.aligned\"\n",
    "# aligned_errors_style2 = \"data/shakespeare/data/align/plays/merged/errors_original.snt.aligned\"\n",
    "\n",
    "# aligned_hamlet_style1 = \"data/shakespeare/data/align/plays/merged/hamlet_modern.snt.aligned\"\n",
    "# aligned_hamlet_style2 = \"data/shakespeare/data/align/plays/merged/hamlet_original.snt.aligned\"\n",
    "\n",
    "# aligned_henryv_style1 = \"data/shakespeare/data/align/plays/merged/henryv_modern.snt.aligned\"\n",
    "# aligned_henryv_style2 = \"data/shakespeare/data/align/plays/merged/henryv_original.snt.aligned\"\n",
    "\n",
    "# aligned_juliuscaesar_style1 = \"data/shakespeare/data/align/plays/merged/juliuscaesar_modern.snt.aligned\"\n",
    "# aligned_juliuscaesar_style2 = \"data/shakespeare/data/align/plays/merged/juliuscaesar_original.snt.aligned\"\n",
    "\n",
    "# style1_tuples = unidecode.unidecode(open(aligned_style1).read())\n",
    "# style2_tuples = unidecode.unidecode(open(aligned_style2).read())\n",
    "\n",
    "# style1_tuples = style1_tuples.split(\"\\n\")\n",
    "# style2_tuples = style2_tuples.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the matter, lieutenant?\n",
      "What's the matter, lieutenant?\n",
      "\n",
      "Tell me this, I pray: Where have you left the money that I gave you?\n",
      "Answer me this, please: where's the money I gave you?\n",
      "\n",
      "Lucius, who's that knocking?\n",
      "Lucius, who's that knocking?\n",
      "\n",
      "Gentlemen, forward to the bridal dinner.\n",
      "Gentlemen, on to the bridal dinner.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"{}\\n{}\\n\".format(agg_original_tuples[0], agg_modern_tuples[0]))\n",
    "print(\"{}\\n{}\\n\".format(agg_original_tuples[5000], agg_modern_tuples[5000]))\n",
    "print(\"{}\\n{}\\n\".format(agg_original_tuples[9000], agg_modern_tuples[9000]))\n",
    "print(\"{}\\n{}\\n\".format(agg_original_tuples[18000], agg_modern_tuples[18000]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42192, 1)\n",
      "(42192, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42192, 3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-class = original = '1'\n",
    "# raw -> (raw text, label)\n",
    "import numpy as np\n",
    "\n",
    "style1_np = np.array(agg_original_tuples)\n",
    "style1_labels = np.array(['1' for x in range(len(agg_original_tuples))])\n",
    "X = np.vstack((style1_np, style1_labels))\n",
    "\n",
    "style2_np = np.array(agg_modern_tuples)\n",
    "style2_labels = np.array(['0' for x in range(len(agg_modern_tuples))])\n",
    "X2 = np.vstack((style2_np, style2_labels))\n",
    "\n",
    "X = np.hstack((X,X2))\n",
    "raw = np.transpose(X)\n",
    "raw.shape\n",
    "\n",
    "idx_col = [str(x) for x in range(len(raw))]\n",
    "idx_col = np.array(idx_col).reshape(-1,1)\n",
    "print(idx_col.shape)\n",
    "print(raw.shape)\n",
    "raw = np.hstack((idx_col, raw))\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2000', 'We looked not for Mark Antony here.', '1'], dtype='<U549')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "features = []\n",
    "\n",
    "\n",
    "# feature engineering\n",
    "    # construct index column\n",
    "idx_col = raw[:,0]\n",
    "\n",
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# stri = 'Go bid the priests do present sacrifice And bring me their opinions of success'\n",
    "# doc = nlp(stri)\n",
    "\n",
    "# for token in doc:\n",
    "#     print(\"{}\\t{}    {} {}\".format(token.text, token.pos_, token.tag_, token.dep_))\n",
    "\n",
    "# adj_count\n",
    "# adverb_count\n",
    "# verb_count\n",
    "# noun_count\n",
    "# adv_verb_ratio\n",
    "# adj_noun ratio\n",
    "\n",
    "# def pos_\n",
    "    \n",
    "sent_len_feature = np.array([-1 for x in range(len(raw))])\n",
    "raw_text_col = 1\n",
    "LABEL_COL = -1\n",
    "\n",
    "for row_idx,_ in enumerate(raw):\n",
    "    sent_len_feature[row_idx] = len(raw[row_idx][raw_text_col])\n",
    "    features.append({'sent_len': len(raw[row_idx][raw_text_col])})\n",
    "    \n",
    "#     if sent_len_feature[row_idx] < 0:\n",
    "#         print(\"sent len less than zero!\")\n",
    "\n",
    "X = vectorizer.fit_transform(features)\n",
    "\n",
    "X = np.vstack((idx_col,sent_len_feature, raw[:,LABEL_COL].astype(float)))\n",
    "X = np.transpose(X)\n",
    "X = X.astype('f', copy=True)\n",
    "# print(X[0:5])\n",
    "# print(X[3700:3705])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., 30.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 42192 traintest split delim: 33753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27277.,    24.,     0.],\n",
       "       [22474.,    32.,     0.],\n",
       "       [15408.,   124.,     1.],\n",
       "       [14384.,   241.,     1.],\n",
       "       [19001.,    81.,     1.],\n",
       "       [  197.,    82.,     1.],\n",
       "       [ 1336.,    19.,     1.],\n",
       "       [14788.,    44.,     1.],\n",
       "       [ 3296.,    27.,     1.],\n",
       "       [32396.,    18.,     0.]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import math\n",
    "# training\n",
    "# test breakout: 3500, 210\n",
    "train_test_split_delim = math.floor(len(X) * .8)\n",
    "print(\"total rows: {} traintest split delim: {}\".format(len(X), train_test_split_delim))\n",
    "# numpy note: addressing [:delim] is exclusive of delim, but\n",
    "#                         [delim:] is inclusive of delim\n",
    "\n",
    "X = np.random.permutation(X)\n",
    "\n",
    "X_train = X[0:train_test_split_delim,1]\n",
    "X_train = X_train.reshape(-1, 1) #TODO: REMOVE\n",
    "Y_train = X[0:train_test_split_delim,LABEL_COL]\n",
    "\n",
    "X_test = X[train_test_split_delim:,1]\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "Y_test = X[train_test_split_delim:,LABEL_COL]\n",
    "\n",
    "logreg = LogisticRegression(random_state=123)\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "X[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "preds = logreg.predict(X_test)\n",
    "test_indices = X[train_test_split_delim:,0]\n",
    "if len(preds) != len(test_indices):\n",
    "    raise ValueError(\"unmatched arrays\")\n",
    "    \n",
    "results = []\n",
    "for (idx, pred) in zip(test_indices,preds):\n",
    "    gold_label = int(raw[int(idx)][-1])\n",
    "    pred_label = int(pred)\n",
    "    #print(\"int'd idx: {} gold label: {} pred label: {}\".format(int(idx), gold_label, pred_label))\n",
    "    \n",
    "    if gold_label == pred_label:\n",
    "          results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "    \n",
    "results[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3967294703163882\n"
     ]
    }
   ],
   "source": [
    "test_len = len(preds)\n",
    "accuracy = sum(preds)/float(test_len)\n",
    "print(\"accuracy: {}\".format(accuracy))\n",
    "\n",
    "#othello accuracy: 0.7428571428571429. but maybe not permuted\n",
    "#all: accuracy: 0.328237942884228\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.zeros(3, dtype=[('row_id','int32'),('text', 'S'), ('label', 'int32')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['9000', \"Lucius, who's that knocking?\", '1'],\n",
       "       ['9001', 'He is a sick man that would speak with you.', '1']],\n",
       "      dtype='<U549')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[9000:9002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go\tVERB    VB aux\n",
      "bid\tVERB    VB ROOT\n",
      "the\tDET    DT det\n",
      "priests\tNOUN    NNS nsubj\n",
      "do\tVERB    VBP ccomp\n",
      "present\tADJ    JJ amod\n",
      "sacrifice\tNOUN    NN dobj\n",
      "And\tCCONJ    CC cc\n",
      "bring\tVERB    VB conj\n",
      "me\tPRON    PRP dative\n",
      "their\tADJ    PRP$ poss\n",
      "opinions\tNOUN    NNS dobj\n",
      "of\tADP    IN prep\n",
      "success\tNOUN    NN pobj\n"
     ]
    }
   ],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# stri = 'Go bid the priests do present sacrifice And bring me their opinions of success'\n",
    "# doc = nlp(stri)\n",
    "\n",
    "# for token in doc:\n",
    "#     print(\"{}\\t{}    {} {}\".format(token.text, token.pos_, token.tag_, token.dep_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
