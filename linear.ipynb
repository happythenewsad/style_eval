{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import random as rd\n",
    "\n",
    "play_file_infixes = ['othello', 'antony-and-cleopatra', 'asyoulikeit', \n",
    "                     'errors', 'hamlet', 'henryv', 'juliuscaesar', 'lear', 'macbeth', \n",
    "                     'merchant', 'msnd', 'muchado', 'richardiii', 'romeojuliet', \n",
    "                     'shrew', 'tempest', 'twelfthnight']\n",
    "play_file_infixes = ['othello']\n",
    "\n",
    "agg_original_tuples = []\n",
    "agg_modern_tuples = []\n",
    "path = \"data/shakespeare/data/align/plays/merged/\"\n",
    "\n",
    "for infix in play_file_infixes:\n",
    "    modern_tuples = unidecode.unidecode(open(path + infix + \"_modern.snt.aligned\").read()).split(\"\\n\")\n",
    "    original_tuples = unidecode.unidecode(open(path + infix + \"_original.snt.aligned\").read()).split(\"\\n\")\n",
    "    agg_original_tuples.extend(original_tuples)\n",
    "    agg_modern_tuples.extend(modern_tuples)\n",
    "# aligned_othello_style1 = \"data/shakespeare/data/align/plays/merged/othello_modern.snt.aligned\"\n",
    "# aligned_othello_style2 = \"data/shakespeare/data/align/plays/merged/othello_original.snt.aligned\"\n",
    "\n",
    "# aligned_ant_cleo_style1 = \"data/shakespeare/data/align/plays/merged/antony-and-cleopatra_modern.snt.aligned\"\n",
    "# aligned_ant_cleo_style2 = \"data/shakespeare/data/align/plays/merged/antony-and-cleopatra_original.snt.aligned\"\n",
    "\n",
    "# aligned_asyoulikeit_style1 = \"data/shakespeare/data/align/plays/merged/asyoulikeit_modern.snt.aligned\"\n",
    "# aligned_asyoulikeit_style2 = \"data/shakespeare/data/align/plays/merged/asyoulikeit_original.snt.aligned\"\n",
    "\n",
    "# aligned_errors_style1 = \"data/shakespeare/data/align/plays/merged/errors_modern.snt.aligned\"\n",
    "# aligned_errors_style2 = \"data/shakespeare/data/align/plays/merged/errors_original.snt.aligned\"\n",
    "\n",
    "# aligned_hamlet_style1 = \"data/shakespeare/data/align/plays/merged/hamlet_modern.snt.aligned\"\n",
    "# aligned_hamlet_style2 = \"data/shakespeare/data/align/plays/merged/hamlet_original.snt.aligned\"\n",
    "\n",
    "# aligned_henryv_style1 = \"data/shakespeare/data/align/plays/merged/henryv_modern.snt.aligned\"\n",
    "# aligned_henryv_style2 = \"data/shakespeare/data/align/plays/merged/henryv_original.snt.aligned\"\n",
    "\n",
    "# aligned_juliuscaesar_style1 = \"data/shakespeare/data/align/plays/merged/juliuscaesar_modern.snt.aligned\"\n",
    "# aligned_juliuscaesar_style2 = \"data/shakespeare/data/align/plays/merged/juliuscaesar_original.snt.aligned\"\n",
    "\n",
    "# style1_tuples = unidecode.unidecode(open(aligned_style1).read())\n",
    "# style2_tuples = unidecode.unidecode(open(aligned_style2).read())\n",
    "\n",
    "# style1_tuples = style1_tuples.split(\"\\n\")\n",
    "# style2_tuples = style2_tuples.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"{}\\n{}\\n\".format(agg_original_tuples[0], agg_modern_tuples[0]))\n",
    "# print(\"{}\\n{}\\n\".format(agg_original_tuples[5000], agg_modern_tuples[5000]))\n",
    "# print(\"{}\\n{}\\n\".format(agg_original_tuples[9000], agg_modern_tuples[9000]))\n",
    "# print(\"{}\\n{}\\n\".format(agg_original_tuples[18000], agg_modern_tuples[18000]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3710, 1)\n",
      "(3710, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3710, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-class = original = '1'\n",
    "# raw -> (raw text, label)\n",
    "import numpy as np\n",
    "\n",
    "style1_np = np.array(agg_original_tuples)\n",
    "style1_labels = np.array(['1' for x in range(len(agg_original_tuples))])\n",
    "X = np.vstack((style1_np, style1_labels))\n",
    "\n",
    "style2_np = np.array(agg_modern_tuples)\n",
    "style2_labels = np.array(['0' for x in range(len(agg_modern_tuples))])\n",
    "X2 = np.vstack((style2_np, style2_labels))\n",
    "\n",
    "X = np.hstack((X,X2))\n",
    "raw = np.transpose(X)\n",
    "raw.shape\n",
    "\n",
    "idx_col = [str(x) for x in range(len(raw))]\n",
    "idx_col = np.array(idx_col).reshape(-1,1)\n",
    "print(idx_col.shape)\n",
    "print(raw.shape)\n",
    "raw = np.hstack((idx_col, raw))\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2000', \"CASSIO  She's awake, sir.\", '0'], dtype='<U497')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the matter, lieutenant? gold: 1 {'sent_len': 30, 'NOUN_count': 3, 'ADV_count': 0, 'VERB_count': 1, 'ADJ_count': 0, 'adv_verb_ratio': 0, 'adj_noun_ratio': 0, 'DET_count': 1, 'PUNCT_count': 2}\n",
      "\n",
      "Therefore, good Emilia, Give me my nightly wearing, and adieu. gold: 1 {'sent_len': 62, 'NOUN_count': 1, 'ADV_count': 2, 'VERB_count': 2, 'ADJ_count': 2, 'adv_verb_ratio': 1.0, 'adj_noun_ratio': 0.5, 'PUNCT_count': 4, 'PROPN_count': 1, 'PRON_count': 1, 'CCONJ_count': 1}\n",
      "\n",
      "CASSIO  She's awake, sir. gold: 0 {'sent_len': 25, 'NOUN_count': 1, 'ADV_count': 0, 'VERB_count': 1, 'ADJ_count': 1, 'adv_verb_ratio': 0, 'adj_noun_ratio': 1.0, 'PROPN_count': 1, 'SPACE_count': 1, 'PRON_count': 1, 'PUNCT_count': 2}\n",
      "\n",
      "Who's shouting? gold: 0 {'sent_len': 15, 'NOUN_count': 1, 'ADV_count': 0, 'VERB_count': 2, 'ADJ_count': 0, 'adv_verb_ratio': 0, 'adj_noun_ratio': 0, 'PUNCT_count': 1}\n",
      "\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(3710, 18)\n",
      "(3710, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import spacy\n",
    "import scipy.sparse\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "print\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "features = []\n",
    "\n",
    "# feature engineering\n",
    "    # construct index column\n",
    "idx_col = np.array([raw[:,0]])\n",
    "idx_col = idx_col.astype('f', copy=True)\n",
    "\n",
    "#sent_len_feature = np.array([-1 for x in range(len(raw))])\n",
    "raw_text_col = 1\n",
    "LABEL_COL = -1\n",
    "\n",
    "for row_idx,_ in enumerate(raw):\n",
    "    feature_dict = {}\n",
    "    pos_dict = {'NOUN_count': 0, 'ADV_count': 0, 'VERB_count': 0, \n",
    "                'ADJ_count': 0, 'adv_verb_ratio': 0, 'adj_noun_ratio': 0}\n",
    "    txt = str(raw[row_idx][raw_text_col])\n",
    "    \n",
    "    feature_dict['sent_len'] = len(txt)\n",
    "    doc = nlp(txt)\n",
    "    for token in doc:\n",
    "        pos = token.pos_\n",
    "        pos_dict[pos+'_count'] = pos_dict.get(pos+'_count', 0) + 1\n",
    "\n",
    "    if pos_dict['NOUN_count'] == 0 or pos_dict['ADJ_count'] == 0:\n",
    "        pos_dict['adj_noun_ratio'] = 0\n",
    "    else:\n",
    "        pos_dict['adj_noun_ratio'] = pos_dict['NOUN_count'] / pos_dict['ADJ_count'] \n",
    "\n",
    "    if pos_dict['VERB_count'] == 0 or pos_dict['ADV_count'] == 0:\n",
    "        pos_dict['adv_verb_ratio'] = 0\n",
    "    else:\n",
    "        pos_dict['adv_verb_ratio'] = pos_dict['VERB_count'] / pos_dict['ADV_count'] \n",
    "        \n",
    "    feature_dict.update(pos_dict)\n",
    "    \n",
    "    if row_idx % 1000 == 0:\n",
    "        print(\"{} gold: {} {}\\n\".format(txt, raw[row_idx][LABEL_COL], feature_dict) )\n",
    "        \n",
    "    features.append(feature_dict)\n",
    "\n",
    "labels_col = np.array([raw[:,LABEL_COL].astype(float)])\n",
    "\n",
    "X = vectorizer.fit_transform(features)\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "print(idx_col.T.shape)\n",
    "X = scipy.sparse.hstack(( idx_col.T, X, labels_col.T ))\n",
    "X = X.todense()\n",
    "# X = np.transpose(X)\n",
    "# X = X.astype('f', copy=True)\n",
    "# print(X[0:5])\n",
    "# print(X[3700:3705])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.,  0.,  1.,  0.,  0.,  2.,  0.,  3.,  0.,  0.,  1.,  0.,  1.,\n",
       "          0.,  2.,  0.,  0.,  0., 42.,  1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 3710 traintest split delim: 2968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import math\n",
    "###############\n",
    "# training ####\n",
    "###############\n",
    "# test breakout: 3500, 210\n",
    "train_test_split_delim = math.floor(len(X) * .8)\n",
    "print(\"total rows: {} traintest split delim: {}\".format(len(X), train_test_split_delim))\n",
    "# numpy note: addressing [:delim] is exclusive of delim, but\n",
    "#                         [delim:] is inclusive of delim\n",
    "last_feat_col = X.shape[1] -2\n",
    "X = np.random.permutation(X)\n",
    "\n",
    "X_train = X[0:train_test_split_delim,1:last_feat_col ]\n",
    "#X_train = X_train.reshape(-1, 1) #TODO: REMOVE\n",
    "Y_train = X[0:train_test_split_delim,LABEL_COL]\n",
    "\n",
    "X_test = X[train_test_split_delim:,1:last_feat_col ]\n",
    "#X_test = X_test.reshape(-1, 1)\n",
    "Y_test = X[train_test_split_delim:,LABEL_COL]\n",
    "\n",
    "logreg = LogisticRegression(random_state=123)\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3710, 20)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "preds = logreg.predict(X_test)\n",
    "test_indices = X[train_test_split_delim:,0]\n",
    "if len(preds) != len(test_indices):\n",
    "    raise ValueError(\"unmatched arrays\")\n",
    "    \n",
    "results = []\n",
    "for (idx, pred) in zip(test_indices,preds):\n",
    "    gold_label = int(raw[int(idx)][-1])\n",
    "    pred_label = int(pred)\n",
    "    #print(\"int'd idx: {} gold label: {} pred label: {}\".format(int(idx), gold_label, pred_label))\n",
    "    \n",
    "    if gold_label == pred_label:\n",
    "          results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "    \n",
    "results[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.4609164420485175\n"
     ]
    }
   ],
   "source": [
    "test_len = len(preds)\n",
    "accuracy = sum(preds)/float(test_len)\n",
    "print(\"accuracy: {}\".format(accuracy))\n",
    "\n",
    "#othello accuracy: 0.7428571428571429. but maybe not permuted\n",
    "#all: accuracy: 0.328237942884228\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.zeros(3, dtype=[('row_id','int32'),('text', 'S'), ('label', 'int32')])\n",
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw[9000:9002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2], [3, 4], [5,6]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array( [[7,8,9]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7, 1, 2],\n",
       "       [8, 3, 4],\n",
       "       [9, 5, 6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(b.T.shape)\n",
    "\n",
    "concat = np.hstack((b.T,a))\n",
    "concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
